{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import rawpy\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.conv1_1 = nn.Conv2d(4, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.upv6 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.conv6_1 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6_2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.upv7 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.conv7_1 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv7_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.upv8 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.conv8_1 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.upv9 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.conv9_1 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv9_2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv10_1 = nn.Conv2d(32, 12, kernel_size=1, stride=1)\n",
    "        \n",
    "    def lrelu(self,x):\n",
    "        outx = torch.max(0.2 * x, x)\n",
    "        return outx\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.normal_(0.0, 0.02)\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                m.weight.data.normal_(0.0, 0.02)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv1 = self.lrelu(self.conv1_1(x))\n",
    "        conv1 = self.lrelu(self.conv1_2(conv1))\n",
    "        pool1 = self.pool1(conv1)\n",
    "\n",
    "        conv2 = self.lrelu(self.conv2_1(pool1))\n",
    "        conv2 = self.lrelu(self.conv2_2(conv2))\n",
    "        pool2 = self.pool1(conv2)\n",
    "\n",
    "        conv3 = self.lrelu(self.conv3_1(pool2))\n",
    "        conv3 = self.lrelu(self.conv3_2(conv3))\n",
    "        pool3 = self.pool1(conv3)\n",
    "\n",
    "        conv4 = self.lrelu(self.conv4_1(pool3))\n",
    "        conv4 = self.lrelu(self.conv4_2(conv4))\n",
    "        pool4 = self.pool1(conv4)\n",
    "\n",
    "        conv5 = self.lrelu(self.conv5_1(pool4))\n",
    "        conv5 = self.lrelu(self.conv5_2(conv5))\n",
    "\n",
    "        up6 = self.upv6(conv5)\n",
    "        up6 = torch.cat([up6, conv4], 1)\n",
    "        conv6 = self.lrelu(self.conv6_1(up6))\n",
    "        conv6 = self.lrelu(self.conv6_2(conv6))\n",
    "\n",
    "        up7 = self.upv7(conv6)\n",
    "        up7 = torch.cat([up7, conv3], 1)\n",
    "        conv7 = self.lrelu(self.conv7_1(up7))\n",
    "        conv7 = self.lrelu(self.conv7_2(conv7))\n",
    "\n",
    "        up8 = self.upv8(conv7)\n",
    "        up8 = torch.cat([up8, conv2], 1)\n",
    "        conv8 = self.lrelu(self.conv8_1(up8))\n",
    "        conv8 = self.lrelu(self.conv8_2(conv8))\n",
    "\n",
    "        up9 = self.upv9(conv8)\n",
    "        up9 = torch.cat([up9, conv1], 1)\n",
    "        conv9 = self.lrelu(self.conv9_1(up9))\n",
    "        conv9 = self.lrelu(self.conv9_2(conv9))\n",
    "\n",
    "        conv10= self.conv10_1(conv9)\n",
    "        out = nn.functional.pixel_shuffle(conv10, 2)\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_raw(raw):\n",
    "    im = raw.raw_image_visible.astype(np.float32) \n",
    "    im = np.maximum(im - 512,0)/ (16383 - 512)\n",
    "\n",
    "    im = np.expand_dims(im,axis=2) \n",
    "    H,W = im.shape[0:2]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2,0:W:2,:], \n",
    "                       im[0:H:2,1:W:2,:],\n",
    "                       im[1:H:2,1:W:2,:],\n",
    "                       im[1:H:2,0:W:2,:]), axis=2)\n",
    "    return out\n",
    "\n",
    "def reduce_mean(out_im, gt_im):\n",
    "    return torch.abs(out_im - gt_im).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 512, 512])\n",
      "0.993025004863739\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.9831347465515137\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.9648302793502808\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.9393985271453857\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.9076499342918396\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.8696839213371277\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.8258010149002075\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.7759066820144653\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.7195701003074646\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.6555753350257874\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.5815359354019165\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.492832750082016\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.3794928789138794\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.21767720580101013\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.19083938002586365\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.2870154082775116\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.23254625499248505\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.08744138479232788\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.07947822660207748\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.10637049376964569\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.10227745026350021\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.08699794113636017\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.0723440945148468\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.0670568197965622\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.057546745985746384\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.04894965887069702\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.05674819275736809\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.05318918079137802\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.04012204334139824\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.033115651458501816\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.05033985897898674\n",
      "torch.Size([32, 3, 512, 512])\n",
      "0.052360206842422485\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "\n",
    "    model=Model().cuda()\n",
    "    loss_function=nn.L1Loss().cuda()\n",
    "    optimizer=optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "    for idx in range(32):\n",
    "        input_tensor=torch.zeros((32,4,256,256),dtype=torch.float32).cuda()\n",
    "        gt_tensor=(torch.ones((32,3,512,512),dtype=torch.float32)).cuda()\n",
    "        output=model(input_tensor)\n",
    "        print(output.size())\n",
    "#         if(idx == 1):\n",
    "#           print(output)\n",
    "        loss=loss_function(output,gt_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
